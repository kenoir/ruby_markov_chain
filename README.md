ruby_markov_chain
=================

A simple ruby implementation of a Markov chain generator using a random walk

   ruby main.rb