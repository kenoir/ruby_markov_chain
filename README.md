ruby_markov_chain
=================

A simple ruby implementation of a Markov chain generator using a random walk


To run:

    ruby main.rb